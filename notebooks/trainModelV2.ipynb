{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import source.Train as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been imported\n",
      "Data has been converted from : \n",
      " [['irrelevant']\n",
      " ['irrelevant']\n",
      " ['purchase']\n",
      " ['find-hotel']\n",
      " ['irrelevant']\n",
      " ['irrelevant']\n",
      " ['irrelevant']\n",
      " ['irrelevant']\n",
      " ['purchase']\n",
      " ['purchase']]\n",
      "\n",
      "to one-hot encoded format : \n",
      " [[0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "example data point :  [0. 0. 0. 0. 0. 0. 0. 1.]  :  Le meilleur cabriolet hybrid moins de 5m10 minimum 400 litres de coffre ?\n"
     ]
    }
   ],
   "source": [
    "x_training, y_training, encoder = train.import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find-around-me\n",
      "find-flight\n",
      "find-hotel\n",
      "find-restaurant\n",
      "find-train\n",
      "irrelevant\n",
      "provide-showtimes\n",
      "purchase\n"
     ]
    }
   ],
   "source": [
    "nlp = train.build_model(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.treat_data(x_training, y_training, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 14.678429586299899}\n",
      "{'textcat': 8.63075733904947}\n",
      "{'textcat': 5.351299897400361}\n",
      "{'textcat': 3.422049814553295}\n",
      "{'textcat': 2.810465239006148}\n",
      "{'textcat': 2.017275685717112}\n",
      "{'textcat': 1.539093528384534}\n",
      "{'textcat': 1.434878255819806}\n",
      "{'textcat': 1.0931025151019833}\n",
      "{'textcat': 0.9951515330897471}\n",
      "model trained and saved\n"
     ]
    }
   ],
   "source": [
    "train.train(train_data, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances de notre model sont évaluées et comparées au model exemple dans le notebook Model_testing.ipynb\n",
    "Afin de l'améliorer, plusieurs technique auraient pu être utilisées :\n",
    "\n",
    "Ici, nous utilisons un système de tokenisation, ainsi que toute une pipeline générale issue de la bibliothèque spacy. Plusieurs techniques étât de l'art, bien que plus lourdes, pourraient améliorer les performances. Il s'agit ensuite de faire un compromis entre temps/coût d'entrainement et performance attendu. Pour un bot commercial, c'est à dire un service qui n'est pas critique, il n'est probablement pas pertinent de dépenser trop d'argent pour gagner un faible pourcentage sur les métriques d'évaluation.\n",
    "\n",
    "Le modèle peut être fortement amélioré avec des données qualitatives, et proprement prétraitées. Ici, les données sont déséquilibrées, avec des classes avec très peu de données. Pour corriger ce problème il serait intéressant de produire, ou d'acheter de nouvelles données dans les catégories les plus défavorisées, ou d'utiliser des technique d'augmentation de donnée.\n",
    "D'autres mesures de prétraitement que la tokenisation existent, (vectorisation...) qui pourraient permettre si implémentées d'améliorer la performance sans augmenter drastiquement le temps de calcul.\n",
    "\n",
    "D'un coté moins technique, l'expérience utilisateur peut bénéficier d'une amélioration continue à l'aide de métrique d'utilisation, notamment sur la satisfaction de l'utilisateur en fonction de la classe, du nombre de classes utilisées en pratique (pour savoir ou renforcer l'entrâinement spécifiquement)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
