{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert\n",
    "Convert files into spaCy’s JSON format for use with the train command and other experiment management functions. The converter can be specified on the command line, or chosen based on the file extension of the input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✘ Can't find converter for json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy convert [input_file] [output_dir] [--file-type] [--converter]\n",
    "# [--n-sents] [--morphology] [--lang]\n",
    "\n",
    "# !! DOESNT WORK !!\n",
    "# input_file='../data/processed/training_set.json'\n",
    "# output_dir='../data/processed_spacy'\n",
    "\n",
    "# !python -m spacy convert $input_file $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Data\n",
    "Analyze, debug, and validate your training and development data. Get useful stats, and find problems like invalid entity annotations, cyclic dependencies,low data labels and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "=========================== Data format validation ===========================\u001b[0m\n",
      "\n",
      "\u001b[2K✔ Corpus is loadable\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Training pipeline: tagger, parser, ner\n",
      "Starting with blank model 'en'\n",
      "0 training docs\n",
      "0 evaluation docs\n",
      "✘ No evaluation docs\n",
      "✔ No overlap between training and evaluation data\n",
      "✘ Low number of examples to train from a blank model (0)\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0mTraceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\__main__.py\", line 33, in <module>\n",
      "    plac.call(commands[command], sys.argv[1:])\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\plac_core.py\", line 367, in call\n",
      "    cmd, result = parser.consume(arglist)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\plac_core.py\", line 232, in consume\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\debug_data.py\", line 404, in debug_data\n",
      "    gold_train_data[\"n_words\"] / gold_train_data[\"n_sents\"],\n",
      "ZeroDivisionError: division by zero\n",
      "\n",
      "ℹ 0 total words in the data (0 unique)\n",
      "ℹ No word vectors present in the model\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "ℹ 0 new labels, 0 existing labels\n",
      "0 missing values (tokens with '-' label)\n",
      "✔ Good amount of examples for all labels\n",
      "✔ Examples without occurrences available for all labels\n",
      "✔ No entities consisting of or starting/ending with whitespace\n",
      "✔ No entities consisting of or starting/ending with punctuation\n",
      "\u001b[1m\n",
      "=========================== Part-of-speech Tagging ===========================\u001b[0m\n",
      "ℹ 0 labels in data (57 labels in tag map)\n",
      "✔ All labels present in tag map for language 'en'\n",
      "\u001b[1m\n",
      "============================= Dependency Parsing =============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy debug-data [lang] [train_path] [dev_path] [--base-model] [--pipeline] [--ignore-warnings] [--verbose] [--no-format]\n",
    "\n",
    "lang='en'\n",
    "train_path='../data/processed_spacy/training_data.json'\n",
    "test_path='../data/processed_spacy/testing_data.json'\n",
    "\n",
    "! python -m spacy debug-data $lang $train_path $test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Train a model. Expects data in spaCy’s JSON format. On each epoch, a model will be saved out to the directory. Accuracy scores and model details will be added to a meta.json to allow packaging the model using the package command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline: ['tagger', 'parser', 'ner']\n",
      "Starting with blank model 'en'\n",
      "Counting training words (limit=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 192, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Python38\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\__main__.py\", line 33, in <module>\n",
      "    plac.call(commands[command], sys.argv[1:])\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\plac_core.py\", line 367, in call\n",
      "    cmd, result = parser.consume(arglist)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\plac_core.py\", line 232, in consume\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
      "  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\cli\\train.py\", line 280, in train\n",
      "    corpus = GoldCorpus(train_path, dev_path, limit=n_examples)\n",
      "  File \"gold.pyx\", line 174, in spacy.gold.GoldCorpus.__init__\n",
      "  File \"gold.pyx\", line 185, in spacy.gold.GoldCorpus.write_msgpack\n",
      "  File \"gold.pyx\", line 230, in read_tuples\n",
      "  File \"gold.pyx\", line 503, in read_json_file\n",
      "  File \"gold.pyx\", line 465, in json_to_tuple\n",
      "KeyError: 'paragraphs'\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy train [lang] [output_path] [train_path] [dev_path]\n",
    "# [--base-model] [--pipeline] [--vectors] [--n-iter] [--n-early-stopping]\n",
    "# [--n-examples] [--use-gpu] [--version] [--meta-path] [--init-tok2vec]\n",
    "# [--parser-multitasks] [--entity-multitasks] [--gold-preproc] [--noise-level]\n",
    "# [--orth-variant-level] [--learn-tokens] [--textcat-arch] [--textcat-multilabel]\n",
    "# [--textcat-positive-label] [--verbose]\n",
    "\n",
    "output_path='../models'\n",
    "\n",
    "!python -m spacy train $lang $output_path $train_path $test_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
